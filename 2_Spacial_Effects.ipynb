{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Life Science\n",
    "\n",
    "## Specie coexistence in a neutral dynamics with enviormental noise\n",
    "\n",
    "Michele Puppin - 1227474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations - Spacial effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from joblib import Parallel, delayed\n",
    "from numba import jit\n",
    "import time\n",
    "import networkx as nx\n",
    "import math\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_degree(G): # Compute the mean degree of a network \n",
    "    \n",
    "    k = 0\n",
    "    N = G.number_of_nodes()\n",
    "    \n",
    "    for i in range(N):\n",
    "        k += G.degree[i]\n",
    "        \n",
    "    k_mean = k/N\n",
    "    \n",
    "    return k_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_isolated(G): # Remove isoleted node in a graph \n",
    "    \n",
    "    for i in list(nx.isolates(G)):\n",
    "\n",
    "        node = random.choice(list(G.nodes()))\n",
    "\n",
    "        while node == i:\n",
    "            node = random.choice(list(G.nodes()))\n",
    "\n",
    "        G.add_edges_from([(i, node)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True) # Decorator for optimization by Numba’s JIT compiler\n",
    "def neighbours(adj,i): # Compute the list of neigbours of node i given the adjacency matrix\n",
    "    \n",
    "    neigh = []\n",
    "    \n",
    "    for j in range(adj.shape[0]):\n",
    "        if adj[i,j] == 1:\n",
    "            neigh.append(j)\n",
    "    \n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative fitness case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True) # Decorator for optimization by Numba’s JIT compiler\n",
    "def voter_model(state, adj, N, sAB, sigma, epsilon): # Update the state of the system\n",
    "    \n",
    "    sA = sAB + sigma * epsilon / 2.0 # Compute the number of seeds \n",
    "    sB = sAB - sigma * epsilon / 2.0\n",
    "    \n",
    "    removed = np.random.randint(N) # Choose uniformly the node to be replaced\n",
    "    \n",
    "    l = neighbours(adj,removed) # Compute the list of neighbours \n",
    "    \n",
    "    nA = 0.0\n",
    "    nB = 0.0\n",
    "    \n",
    "    for i in l:\n",
    "        if state[i] == 0:\n",
    "            nA += 1 # Compute how many neighbours belong to spacies A\n",
    "        if state[i] == 1:\n",
    "            nB += 1 # Compute how many neighbours belong to spacies B\n",
    "        \n",
    "    lambdaA = sA / (sA * nA + sB * nB) # Compute the fitness\n",
    "    #lambdaB = sB / (sA * nA + sB * nB)\n",
    "            \n",
    "    pA = lambdaA * nA # Compute the probablity to be replaced by an individual of species A\n",
    "    #pB = lambdaB * nB\n",
    "    \n",
    "    if random.random() < pA:\n",
    "        state[removed] = 0 # Replace with an individual of species A with probability pA\n",
    "    else: \n",
    "        state[removed] = 1 # Replace with an individual of species B with probability pB\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True) # Decorator for optimization by Numba’s JIT compiler\n",
    "def propagator_rfc(adj, sAB, k, sigma): # Voter model dynamics\n",
    "\n",
    "    N = adj.shape[0] # Number of individuals \n",
    "    # Initial number of individuals of species A and B\n",
    "    state = np.array([0 for i in range(int(N/2))] + [1 for i in range(int(N/2))]) \n",
    "    np.random.shuffle(state) # Individuals are distributed randomly on the network  \n",
    "    \n",
    "    x = random.random() # Initialize state of the environment with uniform probability\n",
    "    if x < 0.5:\n",
    "        epsilon = -1\n",
    "    else: \n",
    "        epsilon = 1\n",
    "        \n",
    "    t = 0.0\n",
    "    dt = 1.0 / N # Time step\n",
    "        \n",
    "    while np.sum(state) != N and np.sum(state) != 0: # Run until species A monodominates or gets extinct\n",
    "        \n",
    "        state = voter_model(state, adj, N, sAB, sigma, epsilon) # Update the state\n",
    "                \n",
    "        t += dt\n",
    "        \n",
    "        if random.random() < (1.0 - np.exp(-k*dt)): # Cheange the environment with probability given by rate k\n",
    "            epsilon = epsilon*(-1.0)\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_mean_time_latt_rfc(N, tau, niterations): # Run the dynamics on a 2D square lattice\n",
    "\n",
    "    sAB = 0.5 # Initialize the number of seed\n",
    "    k = 1.0 / ( 2.0 * tau ) # Compute the rate of the state of the environmental \n",
    "    sigma = 0.25 # Initialize the variability of the environment\n",
    "    \n",
    "    filename = \"latt_rfc_tau\"+str(tau)+\".txt\"\n",
    "\n",
    "    if os.path.exists(filename): \n",
    "        os.remove(filename)\n",
    "\n",
    "    for i in range(len(N)): # Run Voter model dynamics for each population size\n",
    "        print(\"N: \", N[i])\n",
    "        \n",
    "        G_latt = nx.grid_2d_graph(N[i], N[i], periodic=False) # Create a 2D square lattice\n",
    "    \n",
    "        G_latt.add_edges_from([ # Add edges to connect second neighbours\n",
    "            ((x, y), (x+1, y+1))\n",
    "            for x in range(N[i]-1)\n",
    "            for y in range(N[i]-1)\n",
    "        ] + [\n",
    "            ((x+1, y), (x, y+1))\n",
    "            for x in range(N[i]-1)\n",
    "            for y in range(N[i]-1)\n",
    "        ])\n",
    "        adj = nx.to_numpy_matrix(G_latt) # Compute adjacency matrix\n",
    "        \n",
    "        # Run Voter model dynamics in parallel for niterations realizations\n",
    "        res = Parallel(n_jobs=-1, verbose=11)(delayed(propagator_rfc)(adj, sAB, k, sigma) for it_er in range(niterations))\n",
    "                               \n",
    "        with open(filename, \"a\") as f: # Store mean values of extintion time between realizations\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow((N[i]**2, np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = [10, 14, 22, 32, 46, 68, 100, 146, 216, 316] # List of population size\n",
    "tau_list = [1.0/16.0, 1.0/8.0, 1.0/4.0, 1.0/2.0, 1.0, 2.0, 4.0] # List of correlation time values\n",
    "a = [3, 4, 5, 6, 7, 7, 7]\n",
    "niterations = 100 # Number of realizations\n",
    "\n",
    "for i in range(len(tau_list)):\n",
    "    print(\"Tau: \", tau_list[i])\n",
    "    ext_mean_time_latt_rfc(N[0:a[i]], tau_list[i], niterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Erdos-Renji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_mean_time_er_rfc(N, tau, niterations): # Run the dynamics on Erdos-Renj graph\n",
    "\n",
    "    sAB = 0.5 # Initialize the number of seed\n",
    "    k = 1.0 / ( 2.0 * tau ) # Compute the rate of the state of the environmental \n",
    "    sigma = 0.25 # Initialize the variability of the environment\n",
    "    \n",
    "    filename = \"er_rfc_tau\"+str(tau)+\".txt\"\n",
    "\n",
    "    if os.path.exists(filename): \n",
    "        os.remove(filename)\n",
    "\n",
    "    for i in range(len(N)): # Run Voter model dynamics for each population size\n",
    "        print(\"N: \", N[i])\n",
    "        \n",
    "        deg = 8\n",
    "        p = deg/(N[i]-1)\n",
    "        G_ER = nx.erdos_renyi_graph(N[i],p) # Create a Erdos-Renj graph\n",
    "        rm_isolated(G_ER)\n",
    "        print(mean_degree(G_ER)) # Check the degree\n",
    "        adj = nx.to_numpy_matrix(G_ER) # Compute adjacency matrix\n",
    "        \n",
    "        # Run Voter model dynamics in parallel for niterations realizations\n",
    "        res = Parallel(n_jobs=-1, verbose=11)(delayed(propagator_rfc)(adj, sAB, k, sigma) for it_er in range(niterations))\n",
    "\n",
    "        with open(filename, \"a\") as f: # Store mean values of extintion time between realizations\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow((N[i], np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = [math.floor(i/2)*2 for i in np.logspace(2,5,10)] # List of population size\n",
    "tau_list = [1.0/16.0, 1.0/8.0, 1.0/4.0, 1.0/2.0, 1.0, 2.0, 4.0] # List of correlation time values\n",
    "a = [3, 4, 5, 6, 7, 7, 7]\n",
    "niterations = 100 # Number of realizations\n",
    "\n",
    "for i in range(len(tau_list)): # Run for different values of correlation time\n",
    "    print(\"Tau: \", tau_list[i])\n",
    "    ext_mean_time_er_rfc(N[0:a[i]], tau_list[i], niterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Scale-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_mean_time_sf_rfc(N, tau, niterations): # Run the dynamics on Scale Free graph\n",
    "\n",
    "    sAB = 0.5 # Initialize the number of seed\n",
    "    k = 1.0 / ( 2.0 * tau ) # Compute the rate of the state of the environmental \n",
    "    sigma = 0.25 # Initialize the variability of the environment\n",
    "    \n",
    "    filename = \"sf_rfc_tau\"+str(tau)+\".txt\"\n",
    "\n",
    "    if os.path.exists(filename): \n",
    "        os.remove(filename)\n",
    "\n",
    "    for i in range(len(N)): # Run Voter model dynamics for each population size\n",
    "        print(\"N: \", N[i])\n",
    "        \n",
    "        G_SF = nx.barabasi_albert_graph(N[i],4) # Create a Barabasi Albert graph\n",
    "        rm_isolated(G_SF)\n",
    "        print(mean_degree(G_SF))  # Check the degree\n",
    "        adj = nx.to_numpy_matrix(G_SF) # Compute adjacency matrix\n",
    "        \n",
    "        # Run Voter model dynamics in parallel for niterations realizations\n",
    "        res = Parallel(n_jobs=-1, verbose=11)(delayed(propagator_rfc)(adj, sAB, k, sigma) for it_er in range(niterations))\n",
    "\n",
    "\n",
    "        with open(filename, \"a\") as f: # Store mean values of extintion time between realizations\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow((N[i], np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = [math.floor(i/2)*2 for i in np.logspace(2,5,10)] # List of population size\n",
    "tau_list = [1.0/16.0, 1.0/8.0, 1.0/4.0, 1.0/2.0, 1.0, 2.0, 4.0] # List of correlation time values\n",
    "a = [3, 4, 5, 6, 7, 7, 7]\n",
    "niterations = 100 # Number of realizations\n",
    "\n",
    "for i in range(len(tau_list)): # Run for different values of correlation time\n",
    "    print(\"Tau: \", tau_list[i])\n",
    "    ext_mean_time_sf_rfc(N[0:a[i]], tau_list[i], niterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Watts-Strogatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_mean_time_ws_rfc(N, tau, niterations): # Run the dynamics on Watts-Strogatz graph\n",
    "\n",
    "    sAB = 0.5 # Initialize the number of seed\n",
    "    k = 1.0 / ( 2.0 * tau ) # Compute the rate of the state of the environmental \n",
    "    sigma = 0.25 # Initialize the variability of the environment\n",
    "    \n",
    "    filename = \"ws_rfc_tau\"+str(tau)+\".txt\"\n",
    "\n",
    "    if os.path.exists(filename): \n",
    "        os.remove(filename)\n",
    "\n",
    "    for i in range(len(N)): # Run Voter model dynamics for each population size\n",
    "        print(\"N: \", N[i])\n",
    "        \n",
    "        G_WS = nx.watts_strogatz_graph(N[i],8,0.05) # Create a Watts-Strogatz graph\n",
    "        rm_isolated(G_WS)\n",
    "        print(mean_degree(G_WS))  # Check the degree\n",
    "        adj = nx.to_numpy_matrix(G_WS) # Compute adjacency matrix\n",
    "        \n",
    "        # Run Voter model dynamics in parallel for niterations realizations\n",
    "        res = Parallel(n_jobs=-1, verbose=11)(delayed(propagator_rfc)(adj, sAB, k, sigma) for it_er in range(niterations))\n",
    "\n",
    "\n",
    "        with open(filename, \"a\") as f: # Store mean values of extintion time between realizations\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow((N[i], np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = [math.floor(i/2)*2 for i in np.logspace(2,5,10)] # List of population size\n",
    "tau_list = [1.0/16.0, 1.0/8.0, 1.0/4.0, 1.0/2.0, 1.0, 2.0, 4.0] # List of correlation time values\n",
    "a = [3, 4, 5, 6, 7, 7, 7]\n",
    "niterations = 100 # Number of realizations\n",
    "\n",
    "for i in range(len(tau_list)): # Run for different values of correlation time\n",
    "    print(\"Tau: \", tau_list[i])\n",
    "    ext_mean_time_ws_rfc(N[0:a[i]], tau_list[i], niterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
